{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "659abf9b-a024-4dce-bea4-89054917331b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datetime import datetime\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a630d112-1975-4c40-84f8-6f41a23d5d25",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(r'C:\\Users\\MK\\Desktop\\Project_Uno\\World Stock Prices (Daily Updating)\\World Stock Prices Dataset.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b6ee4d81-6ef6-4c08-875c-ef1241fd0acb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df['Date'] = pd.to_datetime(df['Date'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "db0e308b-03f4-4fb6-862c-a5837528e029",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "today = datetime.today().date()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4a3bbad5-8c17-4d42-b663-756869b91385",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                             Date        Open        High         Low  \\\n",
      "0       2023-09-20 00:00:00-04:00    4.840000    4.910000    4.630000   \n",
      "1       2023-09-20 00:00:00-04:00  397.049988  397.989990  386.119995   \n",
      "2       2023-09-20 00:00:00-04:00  564.349976  569.219971  562.659973   \n",
      "3       2023-09-20 00:00:00-04:00  138.550003  139.369995  135.199997   \n",
      "4       2023-09-20 00:00:00-04:00  179.259995  179.699997  175.399994   \n",
      "...                           ...         ...         ...         ...   \n",
      "279748  2023-08-29 00:00:00-04:00   18.719999   18.770000   18.020000   \n",
      "279749  2023-08-30 00:00:00-04:00   18.180000   18.650000   17.879999   \n",
      "279750  2023-08-31 00:00:00-04:00   18.620001   19.850000   18.469999   \n",
      "279751  2023-09-01 00:00:00-04:00   19.660000   20.139999   19.400000   \n",
      "279752  2023-09-05 00:00:00-04:00   19.730000   19.930000   18.820000   \n",
      "\n",
      "             Close    Volume  Dividends  Stock Splits   Brand_Name Ticker  \\\n",
      "0         4.670000   7441900        0.0           0.0      peloton   PTON   \n",
      "1       386.299988   3866600        0.0           0.0      netflix   NFLX   \n",
      "2       563.830017   1311500        0.0           0.0       costco   COST   \n",
      "3       135.289993  46263700        0.0           0.0       amazon   AMZN   \n",
      "4       175.490005  58436200        0.0           0.0        apple   AAPL   \n",
      "...            ...       ...        ...           ...          ...    ...   \n",
      "279748   18.320000   5949600        0.0           0.0  foot locker     FL   \n",
      "279749   18.549999   5829500        0.0           0.0  foot locker     FL   \n",
      "279750   19.620001   6316100        0.0           0.0  foot locker     FL   \n",
      "279751   19.870001   3982400        0.0           0.0  foot locker     FL   \n",
      "279752   18.840000   5862600        0.0           0.0  foot locker     FL   \n",
      "\n",
      "         Industry_Tag Country  \n",
      "0             fitness     usa  \n",
      "1       entertainment     usa  \n",
      "2              retail     usa  \n",
      "3          e-commerce     usa  \n",
      "4          technology     usa  \n",
      "...               ...     ...  \n",
      "279748       footwear     usa  \n",
      "279749       footwear     usa  \n",
      "279750       footwear     usa  \n",
      "279751       footwear     usa  \n",
      "279752       footwear     usa  \n",
      "\n",
      "[279753 rows x 12 columns]\n"
     ]
    }
   ],
   "source": [
    "print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4706460f-8f80-4903-9ce0-fcd1d5211d7a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "17fc030c-8138-4263-b699-6c7d9e9605e9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(r'C:\\Users\\MK\\Desktop\\Project_Uno\\World Stock Prices (Daily Updating)\\World Stock Prices Dataset.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "33b4ac52-0d48-45f4-8cc1-802b574fc388",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df['Date'] = pd.to_datetime(df['Date'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "921069a7-0013-499c-846c-5257a99dfc9a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                        Date        Open        High         Low       Close  \\\n",
      "0  2023-09-20 00:00:00-04:00    4.840000    4.910000    4.630000    4.670000   \n",
      "1  2023-09-20 00:00:00-04:00  397.049988  397.989990  386.119995  386.299988   \n",
      "2  2023-09-20 00:00:00-04:00  564.349976  569.219971  562.659973  563.830017   \n",
      "3  2023-09-20 00:00:00-04:00  138.550003  139.369995  135.199997  135.289993   \n",
      "4  2023-09-20 00:00:00-04:00  179.259995  179.699997  175.399994  175.490005   \n",
      "\n",
      "     Volume  Dividends  Stock Splits Brand_Name Ticker   Industry_Tag Country  \n",
      "0   7441900        0.0           0.0    peloton   PTON        fitness     usa  \n",
      "1   3866600        0.0           0.0    netflix   NFLX  entertainment     usa  \n",
      "2   1311500        0.0           0.0     costco   COST         retail     usa  \n",
      "3  46263700        0.0           0.0     amazon   AMZN     e-commerce     usa  \n",
      "4  58436200        0.0           0.0      apple   AAPL     technology     usa  \n"
     ]
    }
   ],
   "source": [
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e49e4946-0c1b-4d10-ac66-7b29a40b2da0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df.sort_values(by=['Brand_Name', 'Date'], ascending=[True, False], inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "543820ed-c508-4c55-ba36-a862f2305b6b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df.drop_duplicates(subset='Brand_Name', keep='first', inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2cb4b881-dded-47bb-b2da-72d5b9c8d038",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df.to_csv('cleaned_stock_data.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "40a256f1-7fb8-4d01-9785-887869cf8ce8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MK\\AppData\\Local\\Temp\\ipykernel_20580\\3747074266.py:21: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_df['Daily_Return'] = ((filtered_df['Close'] - filtered_df['Open']) / filtered_df['Open']) * 100\n",
      "C:\\Users\\MK\\AppData\\Local\\Temp\\ipykernel_20580\\3747074266.py:24: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_df['Volatility'] = ((filtered_df['High'] - filtered_df['Open']) / filtered_df['Open']) * 100\n",
      "C:\\Users\\MK\\AppData\\Local\\Temp\\ipykernel_20580\\3747074266.py:27: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_df['Daily_Return'] = filtered_df['Daily_Return'].apply(lambda x: f'{x:.2f}%')\n",
      "C:\\Users\\MK\\AppData\\Local\\Temp\\ipykernel_20580\\3747074266.py:28: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_df['Volatility'] = filtered_df['Volatility'].apply(lambda x: f'{x:.2f}%')\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# Load the CSV file into a pandas DataFrame\n",
    "df = pd.read_csv(r'C:\\Users\\MK\\Desktop\\Project_Uno\\Database\\World Stock Prices (Daily Updating)\\World Stock Prices Dataset.csv')\n",
    "\n",
    "# Specify the date format of your 'Date' column\n",
    "date_format = '%Y-%m-%d %H:%M:%S%z'  # Adjust this format to match your data\n",
    "\n",
    "# Convert the 'Date' column to datetime format with the specified date format\n",
    "df['Date'] = pd.to_datetime(df['Date'], format=date_format)\n",
    "\n",
    "# Make the cutoff date offset-aware by specifying the timezone\n",
    "cutoff_date = datetime(2023, 9, 20) - timedelta(days=365 * 5)\n",
    "cutoff_date = cutoff_date.replace(tzinfo=df['Date'].iloc[0].tzinfo)  # Use the timezone from the DataFrame\n",
    "\n",
    "# Filter the DataFrame to keep only the date-times on or after the cutoff date\n",
    "filtered_df = df[df['Date'] >= cutoff_date]\n",
    "\n",
    "# Calculate daily returns using the Open and Close columns\n",
    "filtered_df['Daily_Return'] = ((filtered_df['Close'] - filtered_df['Open']) / filtered_df['Open']) * 100\n",
    "\n",
    "# Calculate Volatility as the percentage difference between Open and High\n",
    "filtered_df['Volatility'] = ((filtered_df['High'] - filtered_df['Open']) / filtered_df['Open']) * 100\n",
    "\n",
    "# Format 'Daily_Return' and 'Volatility' columns as strings with '%' sign\n",
    "filtered_df['Daily_Return'] = filtered_df['Daily_Return'].apply(lambda x: f'{x:.2f}%')\n",
    "filtered_df['Volatility'] = filtered_df['Volatility'].apply(lambda x: f'{x:.2f}%')\n",
    "\n",
    "# Save the cleaned data to a new CSV file\n",
    "filtered_df.to_csv('Official-database-high-low.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "b805b0b9-21c0-4a00-b2ba-36cec374eb33",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MK\\AppData\\Local\\Temp\\ipykernel_20580\\3747074266.py:21: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_df['Daily_Return'] = ((filtered_df['Close'] - filtered_df['Open']) / filtered_df['Open']) * 100\n",
      "C:\\Users\\MK\\AppData\\Local\\Temp\\ipykernel_20580\\3747074266.py:24: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_df['Volatility'] = ((filtered_df['High'] - filtered_df['Open']) / filtered_df['Open']) * 100\n",
      "C:\\Users\\MK\\AppData\\Local\\Temp\\ipykernel_20580\\3747074266.py:27: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_df['Daily_Return'] = filtered_df['Daily_Return'].apply(lambda x: f'{x:.2f}%')\n",
      "C:\\Users\\MK\\AppData\\Local\\Temp\\ipykernel_20580\\3747074266.py:28: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_df['Volatility'] = filtered_df['Volatility'].apply(lambda x: f'{x:.2f}%')\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# Load the CSV file into a pandas DataFrame\n",
    "df = pd.read_csv(r'C:\\Users\\MK\\Desktop\\Project_Uno\\Database\\World Stock Prices (Daily Updating)\\World Stock Prices Dataset.csv')\n",
    "\n",
    "# Specify the date format of your 'Date' column\n",
    "date_format = '%Y-%m-%d %H:%M:%S%z'  # Adjust this format to match your data\n",
    "\n",
    "# Convert the 'Date' column to datetime format with the specified date format\n",
    "df['Date'] = pd.to_datetime(df['Date'], format=date_format)\n",
    "\n",
    "# Make the cutoff date offset-aware by specifying the timezone\n",
    "cutoff_date = datetime(2023, 9, 20) - timedelta(days=365 * 5)\n",
    "cutoff_date = cutoff_date.replace(tzinfo=df['Date'].iloc[0].tzinfo)  # Use the timezone from the DataFrame\n",
    "\n",
    "# Filter the DataFrame to keep only the date-times on or after the cutoff date\n",
    "filtered_df = df[df['Date'] >= cutoff_date]\n",
    "\n",
    "# Calculate daily returns using the Open and Close columns\n",
    "filtered_df['Daily_Return'] = ((filtered_df['Close'] - filtered_df['Open']) / filtered_df['Open']) * 100\n",
    "\n",
    "# Calculate Volatility as the percentage difference between Open and High\n",
    "filtered_df['Volatility'] = ((filtered_df['High'] - filtered_df['Open']) / filtered_df['Open']) * 100\n",
    "\n",
    "# Format 'Daily_Return' and 'Volatility' columns as strings with '%' sign\n",
    "filtered_df['Daily_Return'] = filtered_df['Daily_Return'].apply(lambda x: f'{x:.2f}%')\n",
    "filtered_df['Volatility'] = filtered_df['Volatility'].apply(lambda x: f'{x:.2f}%')\n",
    "\n",
    "# Save the cleaned data to a new CSV file\n",
    "filtered_df.to_csv('Official-database-high-low.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "05f545c4-9b31-4eeb-93ae-48526def8b7e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Brand_Name  AVG ROI  Volatility\n",
      "0    coinbase     0.22        8.25\n",
      "1      airbnb     0.18        4.30\n",
      "2      nvidia     0.15        4.50\n",
      "3       apple     0.13        2.33\n",
      "4        uber     0.11        4.38\n",
      "5  mastercard     0.10        2.32\n",
      "6    logitech     0.10        2.30\n",
      "7       fedex     0.09        2.44\n",
      "8      roblox     0.09        6.71\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# Load the CSV file into a pandas DataFrame\n",
    "df = pd.read_csv(r'C:\\Users\\MK\\Desktop\\Project_Uno\\Database\\World Stock Prices (Daily Updating)\\World Stock Prices Dataset.csv')\n",
    "\n",
    "# Specify the date format of your 'Date' column\n",
    "date_format = '%Y-%m-%d %H:%M:%S%z'  # Adjust this format to match your data\n",
    "\n",
    "# Convert the 'Date' column to datetime format with the specified date format\n",
    "df['Date'] = pd.to_datetime(df['Date'], format=date_format)\n",
    "\n",
    "# Make the cutoff date offset-aware by specifying the timezone\n",
    "cutoff_date = datetime(2023, 9, 20) - timedelta(days=365 * 2)\n",
    "cutoff_date = cutoff_date.replace(tzinfo=df['Date'].iloc[0].tzinfo)  # Use the timezone from the DataFrame\n",
    "\n",
    "# Filter the DataFrame to keep only the date-times on or after the cutoff date\n",
    "filtered_df = df[df['Date'] >= cutoff_date].copy()  # Create a copy to avoid SettingWithCopyWarning\n",
    "\n",
    "# Calculate daily returns using the Open and Close columns\n",
    "filtered_df.loc[:, 'Daily_Return'] = ((filtered_df['Close'] - filtered_df['Open']) / filtered_df['Open']) * 100\n",
    "\n",
    "# Calculate Volatility as the percentage difference between Open and High\n",
    "filtered_df.loc[:, 'Volatility'] = ((filtered_df['High'] - filtered_df['Low']) / filtered_df['Low']) * 100\n",
    "\n",
    "# Check if columns need conversion to numeric\n",
    "if filtered_df['Daily_Return'].dtype == 'object':\n",
    "    filtered_df['Daily_Return'] = filtered_df['Daily_Return'].str.rstrip('%').astype(float)\n",
    "\n",
    "if filtered_df['Volatility'].dtype == 'object':\n",
    "    filtered_df['Volatility'] = filtered_df['Volatility'].str.rstrip('%').astype(float)\n",
    "\n",
    "# Calculate the mean of 'Daily_Return' and 'Volatility' for each 'Brand_Name'\n",
    "averages = filtered_df.groupby('Brand_Name', as_index=False)[['Daily_Return', 'Volatility']].mean()\n",
    "\n",
    "# Rename the 'Daily_Return' column to 'AVG ROI'\n",
    "averages.rename(columns={'Daily_Return': 'AVG ROI'}, inplace=True)\n",
    "\n",
    "# Filter the averages DataFrame to keep only companies with a daily return average >= 0.08\n",
    "filtered_averages = averages[averages['AVG ROI'] >= 0.08]\n",
    "\n",
    "# Filter the filtered_averages DataFrame to keep only companies with average volatility >= 2\n",
    "filtered_averages = filtered_averages[filtered_averages['Volatility'] >= 2]\n",
    "\n",
    "# Sort the filtered_averages DataFrame by 'AVG ROI' in descending order and reset the index\n",
    "filtered_averages = filtered_averages.sort_values(by='AVG ROI', ascending=False).reset_index(drop=True)\n",
    "\n",
    "# Round the 'AVG ROI' and 'Volatility' columns to two decimal places\n",
    "filtered_averages['AVG ROI'] = filtered_averages['AVG ROI'].round(2)\n",
    "filtered_averages['Volatility'] = filtered_averages['Volatility'].round(2)\n",
    "\n",
    "# Display the resulting DataFrame\n",
    "print(filtered_averages)\n",
    "\n",
    "# Save the cleaned data to a new CSV file\n",
    "filtered_averages.to_csv('high-risk-strategy-database.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "52ba711a-6b17-4800-8e8f-f0b94f5f99df",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Brand_Name  Sum_Daily_Return  AVG ROI  Volatility AVG\n",
      "13   coinbase        110.513270     0.15            8.25\n",
      "3      airbnb         93.060188     0.13            4.30\n",
      "36     nvidia         75.614949     0.10            4.50\n",
      "8       apple         63.651088     0.09            2.33\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# Load the CSV file into a pandas DataFrame\n",
    "df = pd.read_csv(r'C:\\Users\\MK\\Desktop\\Project_Uno\\Database\\World Stock Prices (Daily Updating)\\World Stock Prices Dataset.csv')\n",
    "\n",
    "# Specify the date format of your 'Date' column\n",
    "date_format = '%Y-%m-%d %H:%M:%S%z'  # Adjust this format to match your data\n",
    "\n",
    "# Convert the 'Date' column to datetime format with the specified date format\n",
    "df['Date'] = pd.to_datetime(df['Date'], format=date_format)\n",
    "\n",
    "# Make the cutoff date offset-aware by specifying the timezone\n",
    "cutoff_date = datetime(2023, 9, 20) - timedelta(days=365 * 2)\n",
    "cutoff_date = cutoff_date.replace(tzinfo=df['Date'].iloc[0].tzinfo)  # Use the timezone from the DataFrame\n",
    "\n",
    "# Filter the DataFrame to keep only the date-times on or after the cutoff date\n",
    "filtered_df = df[df['Date'] >= cutoff_date].copy()  # Create a copy to avoid SettingWithCopyWarning\n",
    "\n",
    "# Calculate daily returns using the Open and Close columns\n",
    "filtered_df.loc[:, 'Daily_Return'] = ((filtered_df['Close'] - filtered_df['Open']) / filtered_df['Open']) * 100\n",
    "\n",
    "# Calculate Volatility as the percentage difference between Open and High\n",
    "filtered_df.loc[:, 'Volatility'] = ((filtered_df['High'] - filtered_df['Low']) / filtered_df['Low']) * 100\n",
    "\n",
    "# Check if the 'Daily_Return' and 'Volatility' columns need conversion to numeric\n",
    "if filtered_df['Daily_Return'].dtype == 'object':\n",
    "    filtered_df['Daily_Return'] = filtered_df['Daily_Return'].str.rstrip('%').astype(float)\n",
    "\n",
    "if filtered_df['Volatility'].dtype == 'object':\n",
    "    filtered_df['Volatility'] = filtered_df['Volatility'].str.rstrip('%').astype(float)\n",
    "\n",
    "# Calculate the sum of daily returns and average volatility for each 'Brand_Name' over the past 2 years\n",
    "sum_daily_returns = filtered_df.groupby('Brand_Name', as_index=False)['Daily_Return'].sum()\n",
    "avg_volatility = filtered_df.groupby('Brand_Name', as_index=False)['Volatility'].mean()\n",
    "\n",
    "sum_daily_returns.rename(columns={'Daily_Return': 'Sum_Daily_Return'}, inplace=True)\n",
    "avg_volatility.rename(columns={'Volatility': 'Volatility AVG'}, inplace=True)\n",
    "\n",
    "# Calculate 'AVG ROI' as the sum of daily returns divided by (2 * 365)\n",
    "sum_daily_returns['AVG ROI'] = sum_daily_returns['Sum_Daily_Return'] / (2 * 365)\n",
    "\n",
    "# Merge the two DataFrames on 'Brand_Name'\n",
    "merged_df = pd.merge(sum_daily_returns, avg_volatility, on='Brand_Name', how='inner')\n",
    "\n",
    "# Filter the DataFrame to keep only companies with 'AVG ROI' >= 0.08\n",
    "filtered_sum_returns = merged_df[merged_df['AVG ROI'] >= 0.08]\n",
    "\n",
    "# Sort the DataFrame by 'AVG ROI' in descending order\n",
    "filtered_sum_returns = filtered_sum_returns.sort_values(by='AVG ROI', ascending=False)\n",
    "\n",
    "# Round the 'AVG ROI' and 'Volatility AVG' columns to two decimal places\n",
    "filtered_sum_returns['AVG ROI'] = filtered_sum_returns['AVG ROI'].round(2)\n",
    "filtered_sum_returns['Volatility AVG'] = filtered_sum_returns['Volatility AVG'].round(2)\n",
    "\n",
    "# Display the resulting DataFrame\n",
    "print(filtered_sum_returns)\n",
    "\n",
    "# Save the cleaned data to a new CSV file\n",
    "filtered_sum_returns.to_csv('high-risk-strategy-database.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1aa2ad0-ff84-4ea7-b82e-6fedbfa8bc14",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bca6ab78-2d21-4aed-9593-e7120446ae89",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24407bf9-bd49-45c1-b3e0-ebb893310fb5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
